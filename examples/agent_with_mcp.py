#!/usr/bin/env python3
"""
Agent with MCP Example

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯MCPã‚µãƒ¼ãƒãƒ¼ã¨é€£æºã™ã‚‹Agentã®ä¾‹ã§ã™ã€‚
äº‹å‰ã«fastmcpã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã€OpenAI APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚

ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«:
    pip install fastmcp

ä½¿ç”¨æ–¹æ³•:
    export OPENAI_API_KEY="your-openai-api-key"
    python -W ignore examples/agent_with_mcp.py
"""

# !/usr/bin/env python3

# Warningsã‚’æœ€åˆã«æŠ‘åˆ¶
import os
import warnings

os.environ["PYTHONWARNINGS"] = "ignore"
warnings.simplefilter("ignore")
# å…¨ã¦ã®è­¦å‘Šã‚’æŠ‘åˆ¶
warnings.filterwarnings("ignore", category=DeprecationWarning)
warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", message=".*")
import logging

# Rich/fastmcpã®ERRORãƒ­ã‚°ã‚‚æŠ‘åˆ¶
logging.getLogger("rich").setLevel(logging.CRITICAL)
logging.getLogger("fastmcp").setLevel(logging.CRITICAL)

import asyncio
import sys
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "src"))

from ygents.agent.core import Agent
from ygents.agent.models import (
    ContentChunk,
    ErrorMessage,
    ToolError,
    ToolInput,
    ToolResult,
)
from ygents.config.models import YgentsConfig


def create_inmemory_mcp_config():
    """InMemory MCPã‚µãƒ¼ãƒãƒ¼è¨­å®šã‚’ä½œæˆ"""
    try:
        import fastmcp

        # InMemory MCPã‚µãƒ¼ãƒãƒ¼ã‚’ä½œæˆ
        server = fastmcp.FastMCP(name="ExampleServer")

        @server.tool()
        def get_weather(city: str) -> str:
            """æŒ‡å®šã•ã‚ŒãŸéƒ½å¸‚ã®å¤©æ°—ã‚’å–å¾—"""
            # ç°¡å˜ãªãƒ¢ãƒƒã‚¯å¤©æ°—ãƒ‡ãƒ¼ã‚¿
            weather_data = {
                "tokyo": "æ±äº¬: æ™´ã‚Œã€æ°—æ¸©25Â°C",
                "osaka": "å¤§é˜ª: æ›‡ã‚Šã€æ°—æ¸©23Â°C",
                "kyoto": "äº¬éƒ½: é›¨ã€æ°—æ¸©20Â°C",
                "yokohama": "æ¨ªæµœ: æ™´ã‚Œã€æ°—æ¸©24Â°C",
            }

            city_lower = city.lower()
            if city_lower in weather_data:
                return weather_data[city_lower]
            else:
                return f"{city}: å¤©æ°—ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"

        @server.tool()
        def calculate(operation: str, a: float, b: float) -> float:
            """åŸºæœ¬çš„ãªè¨ˆç®—ã‚’å®Ÿè¡Œ"""
            if operation == "add":
                return a + b
            elif operation == "subtract":
                return a - b
            elif operation == "multiply":
                return a * b
            elif operation == "divide":
                if b == 0:
                    raise ValueError("ã‚¼ãƒ­ã§å‰²ã‚‹ã“ã¨ã¯ã§ãã¾ã›ã‚“")
                return a / b
            else:
                raise ValueError(f"æœªçŸ¥ã®æ“ä½œ: {operation}")

        @server.tool()
        def get_time() -> str:
            """ç¾åœ¨æ™‚åˆ»ã‚’å–å¾—"""
            from datetime import datetime

            return datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S")

        return server

    except ImportError:
        print("âŒ fastmcpãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        print("ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„:")
        print("pip install fastmcp")
        return None


async def mcp_agent_example():
    """MCPã‚µãƒ¼ãƒãƒ¼é€£æºAgentä¾‹"""
    print("=== Agent with MCP Example ===")
    print("MCPã‚µãƒ¼ãƒãƒ¼ã¨é€£æºã™ã‚‹Agentã®ä¾‹ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚\n")

    # InMemory MCPã‚µãƒ¼ãƒãƒ¼ã‚’ä½œæˆ
    mcp_server = create_inmemory_mcp_config()
    if not mcp_server:
        return

    # è¨­å®šã‚’ä½œæˆï¼ˆMCPã‚µãƒ¼ãƒãƒ¼ã‚ã‚Šï¼‰
    config = YgentsConfig(
        litellm={
            "model": "openai/gpt-4o",
            "api_key": os.getenv("OPENAI_API_KEY", "")
        },
    )

    # APIã‚­ãƒ¼ã®ç¢ºèª
    if not config.litellm.get("api_key"):
        print("âŒ ã‚¨ãƒ©ãƒ¼: OPENAI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        print("ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„:")
        print("export OPENAI_API_KEY='your-openai-api-key'")
        return

    try:
        async with Agent(config) as agent:
            # InMemory MCPã‚µãƒ¼ãƒãƒ¼ã‚’æ‰‹å‹•ã§æ³¨å…¥ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰
            import fastmcp

            client = fastmcp.Client(mcp_server)
            async with client:
                agent._mcp_client = client
                agent._mcp_client_connected = True

                print("âœ… Agent + MCPåˆæœŸåŒ–å®Œäº†")

                # åˆ©ç”¨å¯èƒ½ãªãƒ„ãƒ¼ãƒ«ã‚’è¡¨ç¤º
                try:
                    tools = await client.list_tools()
                    print(f"ğŸ“‹ åˆ©ç”¨å¯èƒ½ãªãƒ„ãƒ¼ãƒ«: {[tool.name for tool in tools]}")
                except Exception as e:
                    print(f"âš ï¸  ãƒ„ãƒ¼ãƒ«ä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")

                # å„ç¨®è³ªå•ä¾‹
                questions = [
                    "æ±äº¬ã®å¤©æ°—ã‚’æ•™ãˆã¦",
                    "10 + 5 ã‚’è¨ˆç®—ã—ã¦",
                    "ç¾åœ¨æ™‚åˆ»ã‚’æ•™ãˆã¦",
                    "å¤§é˜ªã®å¤©æ°—ã¯ã©ã†ï¼Ÿ",
                ]

                for i, question in enumerate(questions, 1):
                    print(f"\n--- è³ªå• {i} ---")
                    print(f"ğŸ’­ è³ªå•: {question}")
                    print("ğŸ“ å¿œç­”: ", end="", flush=True)

                    # è‡ªå‹•å®Œäº†ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¿½åŠ 
                    question_with_completion = (
                        f"{question} å®Œäº†ã—ãŸã‚‰'å®Œäº†ã—ã¾ã—ãŸ'ã¨è¨€ã£ã¦ãã ã•ã„ã€‚"
                    )

                    try:
                        async for chunk in agent.run(question_with_completion):
                            if isinstance(chunk, ContentChunk):
                                print(chunk.content, end="", flush=True)
                            elif isinstance(chunk, ToolInput):
                                print(f"\nğŸ”§ ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œ: {chunk.tool_name}")
                                print(f"   å¼•æ•°: {chunk.arguments}")
                            elif isinstance(chunk, ToolResult):
                                print(f"âœ… çµæœ: {chunk.result}")
                            elif isinstance(chunk, ToolError):
                                print(f"âŒ ãƒ„ãƒ¼ãƒ«ã‚¨ãƒ©ãƒ¼: {chunk.content}")
                            elif isinstance(chunk, ErrorMessage):
                                print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {chunk.content}")

                        print("")

                    except Exception as e:
                        print(f"\nâŒ è³ªå•å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")

                print("\nâœ… MCPé€£æºãƒ†ã‚¹ãƒˆå®Œäº†")

    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")


async def interactive_mcp_chat():
    """MCPã‚µãƒ¼ãƒãƒ¼é€£æºã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒãƒ£ãƒƒãƒˆ"""
    print("\n=== Interactive MCP Chat ===")
    print("MCPãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã§ãã‚‹ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒãƒ£ãƒƒãƒˆã§ã™ã€‚")
    print("åˆ©ç”¨å¯èƒ½ãªãƒ„ãƒ¼ãƒ«: get_weather, calculate, get_time")
    print("'quit' ã¾ãŸã¯ 'exit' ã§çµ‚äº†ã—ã¾ã™ã€‚\n")

    # InMemory MCPã‚µãƒ¼ãƒãƒ¼ã‚’ä½œæˆ
    mcp_server = create_inmemory_mcp_config()
    if not mcp_server:
        return

    # è¨­å®šã‚’ä½œæˆ
    config = YgentsConfig(
        litellm={
            "model": "openai/gpt-4o",
            "api_key": os.getenv("OPENAI_API_KEY", "")
        },
        mcp_servers={"example_server": {}},
    )

    if not config.litellm.get("api_key"):
        print("âŒ ã‚¨ãƒ©ãƒ¼: OPENAI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return

    try:
        async with Agent(config) as agent:
            import fastmcp

            client = fastmcp.Client(mcp_server)
            async with client:
                agent._mcp_client = client
                agent._mcp_client_connected = True

                print("âœ… MCP Agentæº–å‚™å®Œäº†! ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã£ãŸè³ªå•ã‚’ã—ã¦ãã ã•ã„ã€‚")
                print("ä¾‹: 'æ±äº¬ã®å¤©æ°—ã¯ï¼Ÿ', '10 Ã— 5 ã¯ï¼Ÿ', 'ä»Šä½•æ™‚ï¼Ÿ'\n")

                while True:
                    try:
                        user_input = input("ã‚ãªãŸ: ")
                        if user_input.lower() in ["quit", "exit", "q"]:
                            break

                        if not user_input.strip():
                            continue

                        # è‡ªå‹•å®Œäº†ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¿½åŠ 
                        user_input_with_completion = (
                            f"{user_input} å®Œäº†ã—ãŸã‚‰'å®Œäº†ã—ã¾ã—ãŸ'ã¨è¨€ã£ã¦ãã ã•ã„ã€‚"
                        )

                        print("Agent: ", end="", flush=True)

                        async for chunk in agent.run(user_input_with_completion):
                            if isinstance(chunk, ContentChunk):
                                print(chunk.content, end="", flush=True)
                            elif isinstance(chunk, ToolInput):
                                print(f"\nğŸ”§ {chunk.tool_name} ã‚’å®Ÿè¡Œä¸­...")
                            elif isinstance(chunk, ToolResult):
                                print("âœ… å®Œäº†")
                            elif isinstance(chunk, ToolError):
                                print(f"\nâŒ ãƒ„ãƒ¼ãƒ«ã‚¨ãƒ©ãƒ¼: {chunk.content}")
                            elif isinstance(chunk, ErrorMessage):
                                print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {chunk.content}")

                        print("\n")

                    except KeyboardInterrupt:
                        print("\n\nğŸ‘‹ ãƒãƒ£ãƒƒãƒˆã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                        break
                    except EOFError:
                        print("\n\nğŸ‘‹ ãƒãƒ£ãƒƒãƒˆã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                        break

    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")


async def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("ğŸ¤– Ygents Agent with MCP Example")
    print("=" * 50)

    # MCPé€£æºä¾‹
    await mcp_agent_example()

    # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–MCPãƒãƒ£ãƒƒãƒˆã®å®Ÿè¡Œç¢ºèª
    try:
        choice = input("\nã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–MCPãƒãƒ£ãƒƒãƒˆã‚’è©¦ã—ã¾ã™ã‹ï¼Ÿ (y/n): ")
        if choice.lower() in ["y", "yes"]:
            await interactive_mcp_chat()
    except KeyboardInterrupt:
        pass

    print("\nğŸ‘‹ ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸï¼")


if __name__ == "__main__":
    asyncio.run(main())
