#!/usr/bin/env python3
"""
Simple Agent Example

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ygentsã®Agentã‚¯ãƒ©ã‚¹ã‚’ä½¿ç”¨ã—ãŸåŸºæœ¬çš„ãªä¾‹ã§ã™ã€‚
OpenAI APIã‚­ãƒ¼ã‚’ç’°å¢ƒå¤‰æ•°ã«è¨­å®šã—ã¦ã‹ã‚‰ã”åˆ©ç”¨ãã ã•ã„ã€‚

ä½¿ç”¨æ–¹æ³•:
    export OPENAI_API_KEY="your-openai-api-key"
    python -W ignore examples/simple_agent.py
"""

# !/usr/bin/env python3

# Warningsã‚’æœ€åˆã«æŠ‘åˆ¶
import os
import warnings

os.environ["PYTHONWARNINGS"] = "ignore"
warnings.simplefilter("ignore")
# å…¨ã¦ã®è­¦å‘Šã‚’æŠ‘åˆ¶
warnings.filterwarnings("ignore", category=DeprecationWarning)
warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", message=".*")
import logging

# Rich/fastmcpã®ERRORãƒ­ã‚°ã‚‚æŠ‘åˆ¶
logging.getLogger("rich").setLevel(logging.CRITICAL)
logging.getLogger("fastmcp").setLevel(logging.CRITICAL)

import asyncio
import sys
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "src"))

from ygents.agent.core import Agent
from ygents.agent.models import ContentChunk, ErrorMessage, StatusUpdate
from ygents.config.models import YgentsConfig


async def simple_chat_example():
    """ã‚·ãƒ³ãƒ—ãƒ«ãªãƒãƒ£ãƒƒãƒˆä¾‹"""
    print("=== Simple Agent Example ===")
    print("Agentã¨ã®ç°¡å˜ãªå¯¾è©±ä¾‹ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚\n")

    # è¨­å®šã‚’ä½œæˆ
    config = YgentsConfig(
        litellm={"model": "openai/gpt-4o", "api_key": os.getenv("OPENAI_API_KEY", "")},
        mcp_servers={},  # MCPã‚µãƒ¼ãƒãƒ¼ãªã—ã§å®Ÿè¡Œ
    )

    # APIã‚­ãƒ¼ã®ç¢ºèª
    if not config.litellm.get("api_key"):
        print("âŒ ã‚¨ãƒ©ãƒ¼: OPENAI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        print("ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„:")
        print("export OPENAI_API_KEY='your-openai-api-key'")
        return

    try:
        async with Agent(config) as agent:
            print("âœ… AgentåˆæœŸåŒ–å®Œäº†")
            print("ğŸ’­ è³ªå•: 'ã“ã‚“ã«ã¡ã¯ï¼ä»Šæ—¥ã®å¤©æ°—ã«ã¤ã„ã¦æ•™ãˆã¦ã€‚'")
            print("ğŸ“ å¿œç­”:")

            # Agentã«è³ªå•ï¼ˆãƒ‡ãƒ¢ã®ãŸã‚å›æ•°åˆ¶é™ä»˜ãï¼‰
            user_input = "ã“ã‚“ã«ã¡ã¯ï¼ä»Šæ—¥ã®å¤©æ°—ã«ã¤ã„ã¦æ•™ãˆã¦ã€‚å®Œäº†ã—ãŸã‚‰'å®Œäº†ã—ã¾ã—ãŸ'ã¨è¨€ã£ã¦ãã ã•ã„ã€‚"

            loop_count = 0
            max_loops = 3  # ãƒ‡ãƒ¢ã®ãŸã‚ã®åˆ¶é™

            async for chunk in agent.run(user_input):
                loop_count += 1
                if loop_count > max_loops:
                    print("\nğŸ“Š ãƒ‡ãƒ¢ã®ãŸã‚å‡¦ç†ã‚’åˆ¶é™ã—ã¾ã—ãŸ")
                    break
                if isinstance(chunk, ContentChunk):
                    print(chunk.content, end="", flush=True)
                elif isinstance(chunk, ErrorMessage):
                    print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {chunk.content}")
                elif isinstance(chunk, StatusUpdate):
                    print(f"\nğŸ“Š ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {chunk.content}")

            print("\n\nâœ… å¯¾è©±å®Œäº†")

    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")


async def interactive_chat():
    """ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªãƒãƒ£ãƒƒãƒˆä¾‹"""
    print("\n=== Interactive Agent Chat ===")
    print("Agentã¨ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªå¯¾è©±ã‚’é–‹å§‹ã—ã¾ã™ã€‚")
    print("'quit' ã¾ãŸã¯ 'exit' ã§çµ‚äº†ã—ã¾ã™ã€‚\n")

    # è¨­å®šã‚’ä½œæˆ
    config = YgentsConfig(
        litellm={
            "model": "openai/gpt-3.5-turbo",
            "api_key": os.getenv("OPENAI_API_KEY", ""),
        },
        mcp_servers={},
    )

    if not config.litellm.get("api_key"):
        print("âŒ ã‚¨ãƒ©ãƒ¼: OPENAI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return

    try:
        async with Agent(config) as agent:
            print("âœ… Agentæº–å‚™å®Œäº†! ä½•ã§ã‚‚ãŠèããã ã•ã„ã€‚\n")

            while True:
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
                try:
                    user_input = input("ã‚ãªãŸ: ")
                    if user_input.lower() in ["quit", "exit", "q"]:
                        break

                    if not user_input.strip():
                        continue

                    # è‡ªå‹•å®Œäº†ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¿½åŠ 
                    user_input_with_completion = (
                        f"{user_input} å›ç­”ãŒå®Œäº†ã—ãŸã‚‰'å®Œäº†ã—ã¾ã—ãŸ'ã¨è¨€ã£ã¦ãã ã•ã„ã€‚"
                    )

                    print("Agent: ", end="", flush=True)

                    # Agentå¿œç­”
                    async for chunk in agent.run(user_input_with_completion):
                        if isinstance(chunk, ContentChunk):
                            print(chunk.content, end="", flush=True)
                        elif isinstance(chunk, ErrorMessage):
                            print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {chunk.content}")
                        elif isinstance(chunk, StatusUpdate):
                            print(f"\nğŸ“Š {chunk.content}")

                    print("\n")

                except KeyboardInterrupt:
                    print("\n\nğŸ‘‹ ãƒãƒ£ãƒƒãƒˆã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                    break
                except EOFError:
                    print("\n\nğŸ‘‹ ãƒãƒ£ãƒƒãƒˆã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                    break

    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")


async def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("ğŸ¤– Ygents Agent Example")
    print("=" * 50)

    # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒãƒ£ãƒƒãƒˆä¾‹
    await simple_chat_example()

    # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒãƒ£ãƒƒãƒˆã®å®Ÿè¡Œç¢ºèª
    try:
        choice = input("\nã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒãƒ£ãƒƒãƒˆã‚’è©¦ã—ã¾ã™ã‹ï¼Ÿ (y/n): ")
        if choice.lower() in ["y", "yes"]:
            await interactive_chat()
    except (KeyboardInterrupt, EOFError):
        pass

    print("\nğŸ‘‹ ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸï¼")


if __name__ == "__main__":
    asyncio.run(main())
